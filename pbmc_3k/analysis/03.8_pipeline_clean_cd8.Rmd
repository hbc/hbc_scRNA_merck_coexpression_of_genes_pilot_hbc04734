---
title: "Comparing correlation methods"
author: "Noor Sohail"
output:
   html_document:
      code_folding: hide
      df_print: paged
      highlights: pygments
      number_sections: true
      self_contained: true
      theme: default
      toc: true
      toc_float:
         collapsed: true
         smooth_scroll: true
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Turn off Warnings and other console output messages from the whole document
```

```{r, cache=FALSE, message=FALSE}
library(tidyverse)
library(knitr)
library(glue)
library(Seurat)
library(scales)
library(ggh4x)
library(gridExtra)
library(pheatmap)
library(devtools)

library(CSCORE)
library(WGCNA)
library(ggpubr)
library(ggvenn)

library(SAVER)

ggplot2::theme_set(theme_light(base_size = 11))
opts_chunk[["set"]](
    cache = FALSE,
    dev = c("png", "pdf"),
    error = TRUE,
    highlight = TRUE,
    message = FALSE,
    prompt = FALSE,
    tidy = FALSE,
    warning = FALSE)

theme_arrow <- function() {
    axis <- ggh4x::guide_axis_truncated(
        trunc_lower = unit(0, "npc"),
        trunc_upper = unit(3, "cm")
    )

    list(
        theme_classic() +
        theme(plot.title=element_text(hjust = 0.5, face="bold")) +
        theme(axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
        theme(axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
        theme(axis.title=element_text(size=10, face="bold", hjust=0)) +
        theme(axis.line = element_line(arrow = arrow(type="closed", length=unit(0.5, "cm")), linewidth = 1)),
        guides(x=axis, y=axis)
    )
}

#' Create sub-chunks for plots
#'
#' taken from: https://stackoverflow.com/questions/15365829/dynamic-height-and-width-for-knitr-plots
#'
#' @param pl a plot object
#' @param fig.height figure height
#' @param fig.width figure width
#' @param chunk_name name of the chunk
#'
#' @author Andreas Scharmueller \email{andschar@@protonmail.com}
#'
subchunkify = function(pl,
                       fig.height = 7,
                       fig.width = 5,
                       chunk_name = 'plot') {
  pl_deparsed = paste0(deparse(function() {
    pl
  }), collapse = '')
  
  sub_chunk = paste0(
    "```{r ",
    chunk_name,
    ", fig.height=",
    fig.height,
    ", fig.width=",
    fig.width,
    ", dpi=72",
    ", echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}",
    "\n(",
    pl_deparsed,
    ")()",
    "\n```"
  )
  
  cat(knitr::knit(
    text = knitr::knit_expand(text = sub_chunk),
    quiet = TRUE
  ))
  cat("\n\n")
}
```

# Overview

The overaching goal of this project is to assess different ways of identifying novel co-expressed gene pairs from single-cell RNA-seq datasets. We know that correlations based on the normalized RNA expression are not accurate due to dropout. 

The focus on this report is to compare each method to determine what best practices to use.

The general workflow is:

1. Normalization/imputation
  - We use the raw RNA counts to get a normalized count matrix with:
      1. SCT
      2. MAGIC
      3. SAVER
2. Correlation/Co-expression
  - With these normalized and imputed matrices we can compute spearman correlations on the corrected dataset (resulting in 3 correlation matrices)
  - We supply the raw RNA counts to CS-CORE which will generate a co-expression estimate matrix
3. WGCNA
  - Establish modules of genes by inputting each co-expression matrix into WGCNA

Next we will quantify how well each approach works with the following metrics:

4. Positive and negative controls
5. Consensus across methods
6. Example of finding new co-expressed genes


# Project details

``` {r}
set.seed(2023)

name_project <- "Co-expression of genes"
name_pi <- "Merck"

name_file <- gsub(" ", "_", name_project)
name_file <- gsub("-", "_", name_file)
```

```{r}
path_outs <- "03.8_pipeline_clean_cd8"
```

<b>Dataset background</b>
A brief reminder of what the dataset looks like:

```{r}
# Load dataset
# remotes::install_github("mojaveazure/seurat-disk", quiet=F)
library(SeuratDisk)
load(bzfile("../data/seurat_integrated.RData.bz2"))

seurat <- seurat_integrated
DefaultAssay(seurat) <- "RNA"
seurat[["SCT"]] <- NULL
seurat[["integrated"]] <- NULL

rm(seurat_integrated)
```

```{r}
Idents(object = seurat) <- "integrated_snn_res.0.8"

seurat <- RenameIdents(object = seurat, 
                               "0" = "Naive or memory CD4+ T cells",
                               "1" = "CD14+ monocytes",
                               "2" = "Activated T cells",
                               "3" = "CD14+ monocytes",
                               "4" = "Stressed cells / Unknown",
                               "5" = "CD8+ T cells",
                               "6" = "Naive or memory CD4+ T cells",
                               "7" = "B cells",
                               "8" = "NK cells",
                               "9" = "CD8+ T cells",
                               "10" = "FCGR3A+ monocytes",
                               "11" = "B cells",
                               "12" = "NK cells",
                               "13" = "B cells",
                               "14" = "Conventional dendritic cells",
                               "15" = "Megakaryocytes",
			       "16" = "Plasmacytoid dendritic cells")

seurat$celltype <- Idents(seurat)
Idents(seurat) <- "celltype"
```

```{r fig.height=6}
seurat@meta.data %>%
        ggplot() +
        geom_bar(aes(
            x = celltype,
            fill=celltype),
            stat = "count", color = "black") +
        theme_classic() +
        NoLegend() +
        xlab("Celltype") +
        ylab("Number of Cells") +
        ggtitle(glue("{name_project}\nCelltypes")) +
        theme(plot.title = element_text(hjust = 0.5)) +
        geom_text(aes(x = celltype, label = after_stat(count)), stat = "count", vjust = -0.5) +
        theme(axis.text.x = element_text(angle = 45, hjust=1))
```

```{r fig.height=5, fig.width=7}
Idents(seurat) <- "celltype"
p <- DimPlot(seurat, reduction = "umap") +
    theme_arrow() +
    ggtitle(glue("{name_project}\nCelltypes"))
LabelClusters(p, id = "ident",  fontface = "bold", size = 3, bg.colour = "white", bg.r = .2, force = 0)
```

# Prepping dataset

```{r}
ct <- "CD8+ T cells"
```

This report is going to focus on the `r {ct}` cells.

## Subset dataset

Removing genes that have 0 expression after subsetting cells to one celltype.

```{r}
# seurat <- subset(seurat, subset = (celltype == ct))

# # Removing genes that have 0 counts across all cells of the celltype
# counts <- seurat[["RNA"]]@counts
# genes.use <- rowSums(counts) > 0
# genes.use <- names(genes.use[genes.use])
# seurat <- seurat[genes.use, ]
# rm(counts)
```

## Select surfaceome genes

Generating a list of surfaceome genes that can be found in this celltype.

```{r}
# surfaceome_genes <- read.csv("../data/surfaceome_genes.csv")$x

# # Get the updated list of surfaceome genes found in the dataset
# surfaceome_genes <- surfaceome_genes[surfaceome_genes %in% row.names(seurat[["RNA"]])]

# # Number of cells a gene is expressed in
# data_rna <- FetchData(seurat[["RNA"]], vars=surfaceome_genes)
# num_cells <- colSums(data_rna > 0)

# as.data.frame(surfaceome_genes_all)
```

## Known marker genes

Using some known markers as positive and negative controls for validation.

```{r }
markers <- list()

markers[["CD8"]] <- c("CCL5", "CST7", "GZMB", "CD8A", "PRF1", "CD3D")
markers[["B"]] <- c("CD79A", "MS4A1", "IGHM")
markers[["Monocytes"]] <- c("CD14", "LYZ", "FCGR3A", "MS4A7")

genes <- unname(unlist(markers))

# Dataframe of gene markers
# For clearer plots later on
genes_label <- c()
for (marker in names(markers)) {
  g <- markers[[marker]]
  names(g) <- rep(marker, length(g))

  genes_label <- c(genes_label, g)
}
genes_label <- data.frame(gene=genes_label, celltype=names(genes_label)) %>% column_to_rownames(var="gene")
anno_colors <- list(celltype = c("B"="red", "CD8"="blue", "Monocytes"="green"))

genes_label
```

## Subset surfaceome genes

For this example, I chose the top and bottom 50 genes in the surfaceome dataset based on the average expression and the number of cells they are expressed in. I am additionally including the list of control marker genes from the previous section.

```{r}
# data_sct <- FetchData(seurat[["RNA"]], vars=surfaceome_genes_all, layer="data")

# # Number of cells a gene is expressed in
# # Average expression of a gene
# num_cells <- colSums(data_rna > 0)
# avg_expression <- colMeans(data_rna)

# df_genes <- data.frame(num_cells, avg_expression)
# df_genes$gene <- row.names(df_genes)
# df_genes <- df_genes %>% arrange(desc(avg_expression), desc(num_cells))

# # Select top and bottom genes based on expression and ncells
# surfaceome_genes <- c(head(df_genes, 50)$gene, tail(df_genes, 50)$gene)
# surfaceome_genes <- unique(c(surfaceome_genes, genes))

# # Manually remove B2M because it is an outlier that skews the data
# surfaceome_genes <- surfaceome_genes[surfaceome_genes != "B2M"]

# df_genes[df_genes$gene %in% surfaceome_genes, ]
```

# Input

For this workflow, you only need to supply a seurat object with celltype annotated and a list of genes. 

I have supplied a list of subsetted surfaceome genes as the input for this particular example. 

Bear in mind that as you supply more genes, the computation time will grow exponentially.


# Workflow

## Run SCT

During this step I am re-running SCTransform on the subsetted data. 

```{r}
# # Re-run SCT with hvgs set as surfaceome genes to make sure that they get normalized
# seurat <- seurat[surfaceome_genes, ]
# seurat <- SCTransform(seurat, return.only.var.genes=FALSE, verbose=T)
```

## Normalization/Imputation

We compare three alternative methods of estimating expression levels to log normalization and assess their ability to account for dropout.

1. SCTransform (raw counts -> normalized counts)
2. MAGIC (raw counts -> imputed, normalized counts)
3. SAVER (raw counts -> imputed, normalized counts)

```{r}
# # Get raw counts
# raw_rna <- FetchData(seurat[["RNA"]], vars=surfaceome_genes, layer="counts")

# # LOG NORMALIZATION
# data_rna <- FetchData(seurat[["RNA"]], vars=surfaceome_genes, layer="data")

# # SCT
# data_sct <- FetchData(seurat[["SCT"]], vars=surfaceome_genes, layer="data")

# # MAGIC
# # Load conda environment
# myenvs <- reticulate::conda_list()
# envname <- myenvs$name[3]
# reticulate::use_condaenv(envname, required = TRUE)
# library(Rmagic)
# data_magic <- magic(raw_rna)$result

# # SAVER
# # Generate SAVER predictions for those genes
# data_saver <- saver(t(raw_rna), estimates.only = TRUE, ncores=8)
# data_saver <- data.frame(t(data_saver))
```

```{r}
filename <- glue("{path_outs}/data_list.RDS")

# # Put all matrices in a list for easy access
# data_list <- list(data_rna, data_sct, data_magic, data_saver)
# names(data_list) <- c("rna", "sct", "magic", "saver")

# saveRDS(data_list, filename)

data_list <- readRDS(filename)
```

## Correlation/Co-expression

We have a few different ways to compute correlation scores with their associated p-values:

1. Spearman correlation 
  - SCTransform counts -> spearman correlation matrix
  - MAGIC imputed -> spearman correlation matrix
  - SAVER imputed -> spearman correlation matrix
2. CS-CORE 
    - Raw RNA counts -> co-expression matrix

```{r}
# # Compute spearman correlation for each method (except CS-CORE)
# p_corr_list <- list()
# corr_list <- list()

# # Unique combination of each surfaceome gene pair
# genes_comb <- data.frame(t(combn(surfaceome_genes, 2)))

# for (method in names(data_list)) {
#     data <- data_list[[method]]

#     gene_1_method <- c()
#     gene_2_method <- c()
#     corr_method <- c()
#     p_method <- c()

#     for (idx in 1:nrow(genes_comb)) {

#         gene_1 <- genes_comb[idx, 1]
#         gene_2 <- genes_comb[idx, 2]

#         gene_1_method <- c(gene_1_method, gene_1)
#         gene_2_method <- c(gene_2_method, gene_2)

#         gene_1_exp <- data[[gene_1]]
#         gene_2_exp <- data[[gene_2]]

#         if ((length(gene_1_exp) == 0) | (length(gene_2_exp) == 0 | all(gene_1_exp == 0) | all(gene_2_exp == 0))) {
#             # If a gene has no expression, set correlation = 0 and p-value = 1
#             corr_val <- 0.0
#             p_val <- 1.0
#         } else {
#             # Calculate spearman correlation and p-value otherwise
#             tmp <- cor.test(gene_1_exp, gene_2_exp, method="spearman", exact=F)
#             corr_val <- as.numeric(unname(tmp$estimate))
#             p_val <- as.numeric(tmp$p.value)
#         }

#         corr_method <- c(corr_method, corr_val)
#         p_method <- c(p_method, p_val)

#     }

#     # Data wrangling to put into matrix format
#     corr <- data.frame(Var1=gene_1_method, Var2=gene_2_method, value=corr_method)
#     corr_cp <- corr %>% rename(Var1=Var2, Var2=Var1)
#     corr_cp <- corr_cp[c("Var1", "Var2", "value")]
#     corr <- rbind(corr, corr_cp)
#     corr <- reshape2::dcast(corr, Var2 ~ Var1)
#     rownames(corr) <- corr$Var2
#     corr <- subset(corr, select = -c(Var2))

#     p_corr <- data.frame(Var1=gene_1_method, Var2=gene_2_method, value=p_method)
#     p_corr_cp <- p_corr %>% rename(Var1=Var2, Var2=Var1)
#     p_corr_cp <- p_corr_cp[c("Var1", "Var2", "value")]
#     p_corr <- rbind(p_corr, p_corr_cp)
#     p_corr <- reshape2::dcast(p_corr, Var2 ~ Var1)
#     rownames(p_corr) <- p_corr$Var2
#     p_corr <- subset(p_corr, select = -c(Var2))



#     # Set the diagonal values
#     # Correlation = 1, p-value = 1
#     corr <- as.matrix(corr)
#     diag(corr) <- 1

#     p_corr <- as.matrix(p_corr)
#     diag(p_corr) <- 1

#     # Store results
#     p_corr_list[[method]] <- p_corr
#     corr_list[[method]] <- corr

# }
```

```{r}
# # Run CS-CORE
# CSCORE_result <- CSCORE(seurat, genes = surfaceome_genes)

# corr_list[["cscore"]] <- CSCORE_result$est
# p_corr_list[["cscore"]] <- CSCORE_result$p_value
```


```{r}
# # Co-expression/correlation p-values for each method
# comp_p_corr <- reshape2::melt(as.matrix(p_corr_list[["rna"]])) %>% rename(rna=value)

# for (method in c("sct", "magic", "saver", "cscore")) {
#     df <- as.matrix(p_corr_list[[method]])
#     df <- reshape2::melt(df)
#     colnames(df) <- c("Var1", "Var2", method)

#     comp_p_corr <- merge(comp_p_corr, df)
# }

# cols_round <- c("rna", "sct", "magic", "saver", "cscore")
# comp_p_corr[cols_round] <- round(comp_p_corr[cols_round], 3)
# write.csv(comp_p_corr, glue("{path_outs}/comp_p_corr.csv"))


comp_p_corr <- read.csv(glue("{path_outs}/comp_p_corr.csv"), row.names=1)
```

## WGCNA

WGCNA identifies modules of highly correlated genes, which can help us identify candidate gene pairs with high lilelihood of coexpression. We can supply either the CS-CORE correlation estimate or the spearman correlation matrix to compare methods. 

Additionally, I am optimizing a "soft thresholding" parameter as well as a few other parameters within WGCNA. I am still in the process of selecting the best parameters for MAGIC and SAVER (the authors of CS-CORE provided parameters that already work well).

```{r}
# # Soft threshold parameters for WGCNA
# power_list <- list()
# power_list[["rna"]] <- 2
# power_list[["sct"]] <- 1
# power_list[["magic"]] <- 1
# power_list[["saver"]] <- 4
# power_list[["cscore"]] <- 1


# run_wgcna <- function(mtx_coex, mtx_pval, genes, power) {
#   # Obtain BH-adjusted p values
#   p_matrix_BH <- matrix(0, length(genes), length(genes))
#   p_matrix_BH[upper.tri(p_matrix_BH)] <- p.adjust(mtx_pval[upper.tri(mtx_pval)], method = "BH")
#   p_matrix_BH <- p_matrix_BH + t(p_matrix_BH)

#   # Set co-expression entires with BH-adjusted p-values greater than 0.05 to 0
#   mtx_coex[p_matrix_BH > 0.05] <- 0

#   adj <- WGCNA::adjacency.fromSimilarity(abs(mtx_coex), power = power)

#   # Compute the topological overlap matrix
#   TOM <- WGCNA::TOMsimilarity(adj)
#   dissTOM <- 1 - TOM
#   rownames(dissTOM) <- colnames(dissTOM) <- genes
#   # Run hierarchical clustering as in the WGCNA workflow
#   hclust_dist <- hclust(as.dist(dissTOM), method = "average") 
#   memb <- dynamicTreeCut::cutreeDynamic(dendro = hclust_dist, 
#                       distM = dissTOM, 
#                       deepSplit = 2,
#                       pamRespectsDendro = FALSE,
#                       minClusterSize = 20)

#   # For more instructions on how to tune the parameters in the WGCNA workflow,
#   # please refer to https://horvath.genetics.ucla.edu/html/CoexpressionNetwork/Rpackages/WGCNA/Tutorials/

#   names(memb) <- genes
#   memb_tab <- table(memb)
#   module_list <- lapply(sort(unique(memb)), function(i_k) names(which(memb == i_k)))

#   module_df <- data.frame(memb)
#   module_df$memb <- as.character(module_df$memb)
#   df <- module_df
#   df <- tibble::rownames_to_column(df, "gene")
#   colnames(df) <- c("gene", "module")

#   # Return both the modules and BH-adjust matrix
#   results <- list()
#   results[["wgcna"]] <- df
#   results[["bh_mtx"]] <- mtx_coex

#   return(results)
# }
```

```{r}
# wgcna_list <- list()
# bh_mtx_list <- list()

# for (method in names(corr_list)) {
#     corr <- corr_list[[method]]
#     p_corr <- p_corr_list[[method]]
#     power <- power_list[[method]]

#     # Run WGCNA
#     results <- run_wgcna(corr, p_corr, surfaceome_genes, power=power)
#     wgcna_list[[method]] <- results$wgcna
#     bh_mtx_list[[method]] <- results$bh_mtx
# }
```

```{r}
# # Co-expression/correlation scores for each method
# comp_corr <- reshape2::melt(bh_mtx_list[["rna"]]) %>% rename(rna=value)

# for (method in c("sct", "magic", "saver", "cscore")) {
#     df <- bh_mtx_list[[method]]
#     df <- reshape2::melt(df)
#     colnames(df) <- c("Var1", "Var2", method)

#     comp_corr <- merge(comp_corr, df)
# }

# cols_round <- c("rna", "sct", "magic", "saver", "cscore")
# comp_corr[cols_round] <- round(comp_corr[cols_round], 3)


# write.csv(comp_corr, glue("{path_outs}/comp_corr.csv"))
# saveRDS(bh_mtx_list, glue("{path_outs}/bh_mtx_list.RDS"))


comp_corr <- read.csv(glue("{path_outs}/comp_corr.csv"), row.names=1)
bh_mtx_list <- readRDS(glue("{path_outs}/bh_mtx_list.RDS"))
```

# Comparison

Now that we have all the co-expression estimates from each method, we want to test how well each method agrees with one another. However, we do not need to consider every single gene pair as some of them are of low quality which we can filter out.

```{r}
methods <- c("rna", "sct", "saver", "magic")

# # For each method, calculate the average expression for each gene
# comp_avg <- data.frame(gene=surfaceome_genes) 
# for (method in methods) {
#     print(method)
#     df <- data_list[[method]]
#     df <- data.frame(colMeans(df))
#     colnames(df) <- c(method)
#     row.names(df) <- str_replace(row.names(df), "\\.", "-")

#     df$gene <- rownames(df)
#     comp_avg <- left_join(comp_avg, df, by="gene")

#     print(dim(comp_avg)[1])
# }
# comp_avg <- comp_avg %>% column_to_rownames(var="gene")

# # Number of cells a gene is expressed in across each method
# comp_n_cells <- data.frame(gene=surfaceome_genes)
# for (method in methods) {

#     df <- data_list[[method]]
#     df <- data.frame(colSums(df > 0))
#     colnames(df) <- method
#     row.names(df) <- str_replace(row.names(df), "\\.", "-")
    
#     df$gene <- rownames(df)
#     comp_n_cells <- left_join(comp_n_cells, df, by="gene")
# }
# comp_n_cells <- comp_n_cells %>% column_to_rownames(var="gene")


# write.csv(comp_avg, glue("{path_outs}/comp_avg.csv"))
# write.csv(comp_n_cells, glue("{path_outs}/comp_n_cells.csv"))

comp_avg <- read.csv(glue("{path_outs}/comp_avg.csv"), row.names=1)
comp_n_cells <- read.csv(glue("{path_outs}/comp_n_cells.csv"), row.names=1)

surfaceome_genes <- row.names(comp_avg)
```

## Before filtering

First we need to select good filtration parameters by looking at QC values for each gene.

Here we look at the summary statistics for the **average expression** of genes within each method. Bear in mind the CS-CORE does not provide a normalized/imputed matrix - hence why all the values are NA.

```{r}
summary(comp_avg)
```

```{r}
min_exp <- 0.2
min_cells <- 40
min_perc <- 0.2

n_cells <- dim(data_list[["rna"]])[1]
if (min_perc * n_cells < 30) {
    min_perc <- 30 / n_cells
}
```

Histogram of the average expression for each gene.

```{r}
methods <- c("rna", "sct", "magic", "saver")
palette <- hue_pal()(length(methods))

plot_list <- list()
for (idx in 1:4) {
    method <- methods[idx]
    color <- palette[idx]

    p <- ggplot(comp_avg) +
        geom_histogram(aes(x=get(method)), fill=color, bins=50, alpha=0.5) +
        theme_classic() +
        labs(x="Average expression") +
        ggtitle(method) +
        geom_vline(xintercept = min_exp, color="black", size=1.5, linetype="dashed")

    plot_list[[idx]] <- p

}

cowplot::plot_grid(plotlist=plot_list, ncol=2)
```

Histogram of the number of cells each gene is expressed in based upon the log-normalized expression.

```{r}
ggplot(comp_n_cells) +
    geom_histogram(aes(x=rna), bins=50, alpha=0.5, color="black", fill=palette[1]) +
    theme_classic() +
    labs(x="Number of cells") +
    ggtitle("RNA number of cells") +
   geom_vline(xintercept = min_cells, color="black", size=1.5, linetype="dashed")
```

Histogram of the percentage of cells each gene is expressed in based upon the log-normalized expression (rna).


```{r}
comp_perc_cells <- comp_n_cells / n_cells

ggplot(comp_perc_cells) +
    geom_histogram(aes(x=rna), bins=50, alpha=0.5, color="black", fill=palette[1]) +
    theme_classic() +
    labs(x="Percentage of cells") +
    ggtitle("RNA percentage of cells") +
    geom_vline(xintercept = min_perc, color="black", size=1.5, linetype="dashed")
```

Now I compare each method against one another by plotting the correlation scores for each gene pair. Any pairs that would be filtered by the thresholds (listed below) are highlighted in red on the scatterplots. Only one gene in the pair needs to fail this metric to be filtered out.


- average expression < `r min_exp`
- number of cells expressed in > `r min_cells`
- percentag of cells expressed in > `r min_perc`


For CS-CORE which does not provide a count matrix, I am using the values from whichever method it is being compared against (RNA, SCT, MAGIC, SAVER).

```{r fig.height=12.5, fig.width=12.5}
methods <- names(bh_mtx_list)
plot_list <- list()
idx <- 1

df <- subset(comp_corr, !(Var1 == Var2))
filter_genes <- comp_n_cells %>% subset(rna < min_cells)
filter_genes <- row.names(filter_genes)
tmp <- comp_perc_cells %>% subset(rna < min_perc)
filter_genes <- unique(c(filter_genes, row.names(tmp)))

for (method_1 in methods) {
    for (method_2 in methods) {

        if (method_1 == "cscore") {comp_avg$cscore = comp_avg[[method_2]]}
        if (method_2 == "cscore") {comp_avg$cscore = comp_avg[[method_1]]}
        
        tmp <- comp_avg %>% subset((get(method_1) < min_exp) & (get(method_2) < min_exp))
        tmp <- row.names(tmp)
        genes_filter <- sort(unique(c(filter_genes, tmp)))

        df <- df %>% mutate(filter = (Var1 %in% genes_filter) | (Var2 %in% genes_filter))
        df <- df %>% arrange(filter)

        p <- ggplot(df) +
            geom_point(aes(x=df[[method_1]], y=df[[method_2]], color=df[["filter"]])) +
            scale_color_manual(values = c("FALSE" = "black", "TRUE" = "red")) +
            theme_classic() +
            NoLegend() +
            labs(x=method_1, y=method_2) +
            ggtitle(paste(method_1, "vs", method_2)) +
            ylim(-1, 1) +
            xlim(-1, 1)


        plot_list[[idx]] <- ggplotGrob(p)

        idx <- idx + 1
    }
}
grid.arrange(grobs=plot_list, ncol=5)
```

## After filtration

Once we apply the filter, these are the gene pairs that remain.

```{r fig.height=12.5, fig.width=12.5}
methods <- names(bh_mtx_list)
plot_list <- list()
idx <- 1

df <- subset(comp_corr, !(Var1 == Var2))
filter_genes <- comp_n_cells %>% subset(rna < min_cells)
filter_genes <- row.names(filter_genes)
tmp <- comp_perc_cells %>% subset(rna < min_perc)
filter_genes <- unique(c(filter_genes, row.names(tmp)))


for (method_1 in methods) {
    for (method_2 in methods) {

        if (method_1 == "cscore") {comp_avg$cscore = comp_avg[[method_2]]}
        if (method_2 == "cscore") {comp_avg$cscore = comp_avg[[method_1]]}
        
        tmp <- comp_avg %>% subset((get(method_1) < min_exp) & (get(method_2) < min_exp))
        tmp <- row.names(tmp)
        genes_filter <- sort(unique(c(filter_genes, tmp)))

        df <- df %>% mutate(filter = (Var1 %in% genes_filter) | (Var2 %in% genes_filter))
        df <- df %>% subset(filter == FALSE)


        p <- ggplot(df) +
            geom_point(aes(x=df[[method_1]], y=df[[method_2]], color=df[["filter"]])) +
            scale_color_manual(values = c("FALSE" = "black", "TRUE" = "red")) +
            theme_classic() +
            NoLegend() +
            labs(x=method_1, y=method_2) +
            ggtitle(paste(method_1, "vs", method_2)) +
            ylim(-1, 1) +
            xlim(-1, 1) +
            geom_abline(slope=1, intercept=0, color="red")


        plot_list[[idx]] <- ggplotGrob(p)

        idx <- idx + 1
    }
}
grid.arrange(grobs=plot_list, ncol=5)
```

# Takeaways

I believe these filtration parameters are good minimum values to start with. As we can see that the gene pairs that are removed come primarily from the middle of the plots - representing gene pairs that are lowly correlated.

# Known marker genes

Here I am representing each combination of the known `r ct` marker genes, showing first how well the gene pairs correlate across method and then taking a look at the expression values of each pair. 

Ideally we would see positive correlation scores for each of these gene pairs across all methods.

```{r fig.height=25, fig.width=25}  
methods <- names(bh_mtx_list)
plot_list <- list()
idx <- 1

df <- subset(comp_corr, !(Var1 == Var2))
comp_avg$cscore <- comp_avg$rna
comp_n_cells$cscore <- comp_n_cells$rna

filter_genes <- comp_n_cells %>% subset(rna < min_cells)
filter_genes <- row.names(filter_genes)
tmp <- comp_perc_cells %>% subset(rna < min_perc)
filter_genes <- unique(c(filter_genes, row.names(tmp)))


for (method_1 in methods) {
    for (method_2 in methods) {

        df <- df %>% subset((Var1 %in% markers[["CD8"]]) & (Var2 %in% markers[["CD8"]]))

        tmp <- comp_avg %>% subset((get(method_1) < min_exp) & (get(method_2) < min_exp))
        tmp <- row.names(tmp)
        genes_filter <- sort(unique(c(filter_genes, tmp)))
        df <- df %>% mutate(filter = (Var1 %in% genes_filter) | (Var2 %in% genes_filter))


        p <- ggplot(df) +
            geom_point(aes(x=df[[method_1]], y=df[[method_2]], fill=df[["filter"]])) +
            theme_classic() +
            NoLegend() +
            labs(x=method_1, y=method_2) +
            ggtitle(paste(method_1, "vs", method_2)) +
            ylim(-1, 1) +
            xlim(-1, 1) +
            geom_abline(slope=1, intercept=0, color="red")


        plot_list[[idx]] <- ggplotGrob(p)

        idx <- idx + 1
    }
}

grid.arrange(grobs=plot_list, ncol=5)
```

For every combination of the `r ct` marker genes, I am showing the correlation score calculated for each method.

```{r}
df <- df[!duplicated(cbind(t(apply(df[1:2], 1, sort)), df[-(1:2)])), ]
df
```


## Each marker gene pair

To better understand how well our positive controls are working, I am showing the gene expression and QC metrics for each gene pair using a function I have created called `gene_lookup()`. 

It is important to note that if one gene is expressed much more highly compared to the other, most methods tend to give negative values for their correlation as the highly expressed gene weighs down the calculation.

```{r}
comp_n_cells$cscore <- NA
comp_n_cells$gene <- row.names(comp_n_cells)

comp_perc_cells$cscore <- NA
comp_perc_cells$gene <- row.names(comp_perc_cells)


comp_avg$cscore <- NA
comp_avg$gene <- row.names(comp_avg)

gene_lookup <- function(gene_1, gene_2) {
    cols <- c("metric", "gene", "rna", "sct", "magic", "saver", "cscore")

    n_cells <- comp_n_cells %>% subset(gene %in% c(gene_1, gene_2))
    n_cells$metric <- "n_cells"

    perc_cells <- comp_perc_cells %>% subset(gene %in% c(gene_1, gene_2))
    perc_cells$metric <- "perc_cells"

    avg <- comp_avg %>% subset(gene %in% c(gene_1, gene_2))
    avg$metric <- "avg"

    summary_gene <- rbind(n_cells, perc_cells, avg)
    summary_gene <- summary_gene[cols] %>% remove_rownames()
    cat(knitr::knit_print(summary_gene))
    # print(summary_gene)
    cat("\n\n")

    corr <- comp_corr %>% subset((Var1 == gene_1) & (Var2 == gene_2))
    rownames(corr) <- "correlation"
    p_corr <- comp_p_corr %>% subset((Var1 == gene_1) & (Var2 == gene_2))
    rownames(p_corr) <- "p-value"

    summary_corr <- rbind(corr, p_corr)
    cat(knitr::knit_print(summary_corr))
    # print(summary_corr)
    cat("\n\n")

    corr <- comp_corr %>% subset((Var1 == gene_1) & (Var2 == gene_2))

    plot_list <- list()
    methods <- c("rna", "sct", "magic", "saver")
    # methods <- c("rna", "magic", "saver")

    data <- data_list[["rna"]][c(gene_1, gene_2)]
    dropout_id_1 <- row.names(data[(data[gene_1] == 0.0), ])
    dropout_id_2 <- row.names(data[(data[gene_2] == 0.0), ])
    dropout_id_3 <- row.names(data[((data[gene_2] == 0.0) & (data[gene_1] == 0.0)), ])

    for (method in methods) {
        data <- data_list[[method]]
        colnames(data) <- str_replace(colnames(data), "\\.", "-")

        data$dropout <- NA
        data[dropout_id_1, "dropout"]  <- gene_1
        data[dropout_id_2, "dropout"]  <- gene_2
        data[dropout_id_3, "dropout"]  <- "both"

        corr_method <- corr[[method]]
        p_corr_method <- p_corr[[method]]
        color <- "black"
    

        p <- ggplot(data, aes(x=get(gene_1), y=get(gene_2), color=dropout)) +
                geom_point() +
                theme_classic() +
                xlab(gene_1) + ylab(gene_2) +
                ggtitle(glue("{method}: correlation = {corr_method}")) +
                NoLegend()
                
        plot_list[[method]] <- p
    }

    p <- cowplot::plot_grid(plotlist=plot_list, ncol=2)
    return(p)
    # print(p)
}
```

```{r results="asis"}
for (idx in 1:nrow(df)) {
    gene_1 <- as.character(df[idx, "Var1"])
    gene_2 <- as.character(df[idx, "Var2"])

    cat(glue("### {gene_1} + {gene_2}\n\n"))

    cat("\n\nThe first table includes averaged information for each individual gene. Please note that cscore has NA values as it does not return a count matrix with which we can compute these values. The second table contains the correlation scores and associated p-values.\n\n")

    p <- gene_lookup(gene_1, gene_2)

    cat("\n\nHere we look at the gene expression for each normalization/imputation method. In green and blue we see cells that have expression for one gene but not the other originally. Similarly, the pink points are cells that have 0 expression for both genes.\n\n")

    subchunkify(p, 8, 8, glue("{gene_1}_{gene_2}"))
}
```


# Potential stopping point

Based on all the work we have done previously, I believe that the results from SAVER and CSCORE are more reliable and tend to agree well.

We advocate using a consensus-based appreach, where the final output contains pairs where there is agreement between SAVER and CS-CORE. In this case, we would remove the cases where one method gives a value of 0 while the other does not (we will look more in depth at these cases in the next section).

```{r}
df <- comp_corr %>% subset(saver!=0 & cscore!=0)
df <- df %>% subset(Var1 != Var2)

filter_genes <- comp_n_cells %>% subset(rna < min_cells)
filter_genes <- row.names(filter_genes)
tmp <- comp_perc_cells %>% subset(rna < min_perc)
filter_genes <- unique(c(filter_genes, row.names(tmp)))

tmp <- comp_avg %>% subset(saver < min_exp)
tmp <- row.names(tmp)
genes_filter <- sort(unique(c(filter_genes, tmp)))

df <- df %>% mutate(filter = (Var1 %in% genes_filter) | (Var2 %in% genes_filter))
df <- df %>% subset(filter == FALSE)
df <- df[!duplicated(cbind(t(apply(df[1:2], 1, sort)))), ]

method_1 <- "saver"
method_2 <- "cscore"
ggplot(df) +
    geom_point(aes(x=df[[method_1]], y=df[[method_2]], fill=df[["filter"]])) +
    theme_classic() +
    NoLegend() +
    labs(x=method_1, y=method_2) +
    ggtitle(paste(method_1, "vs", method_2)) +
    ylim(-1, 1) +
    xlim(-1, 1) +
    geom_abline(slope=1, intercept=0, color="red")
```


With the final table of genes like so:

```{r}
df <- df %>% arrange(desc(saver), desc(cscore))
df
```

## Example

Using the `gene_lookup()` function, we can supply the first gene pair listed to look at the summary information of the pair.

```{r results="asis"}
gene_1 <- df[1, "Var1"]
gene_2 <- df[1, "Var2"]
p <- gene_lookup(gene_1, gene_2)
subchunkify(p, 8, 8, glue("{gene_1}_{gene_2}"))
```


# When SAVER and CSCORE don't agree

There are several instances where we see negative correlations from SAVER despite both genes being well expressed together. A cursory look shows that many of these instances occur when there is a large difference in the average expression of the two gene pairs in question. Therefore I am going to look more closely at the ratio between average expressions to see how these values impact the final results.

Here we subset the gene pairs the the aforementioned cases only.

```{r}
df <- comp_corr %>% subset((saver==0 & cscore!=0) | (saver!=0 & cscore==0))
df <- df %>% subset(Var1 != Var2)

filter_genes <- comp_n_cells %>% subset(rna < min_cells)
filter_genes <- row.names(filter_genes)
tmp <- comp_perc_cells %>% subset(rna < min_perc)
filter_genes <- unique(c(filter_genes, row.names(tmp)))

tmp <- comp_avg %>% subset(saver < min_exp)
tmp <- row.names(tmp)
genes_filter <- sort(unique(c(filter_genes, tmp)))

df <- df %>% mutate(filter = (Var1 %in% genes_filter) | (Var2 %in% genes_filter))
df <- df %>% subset(filter == FALSE)
df <- df[!duplicated(cbind(t(apply(df[1:2], 1, sort)))), ]

method_1 <- "saver"
method_2 <- "cscore"
ggplot(df) +
    geom_point(aes(x=df[[method_1]], y=df[[method_2]], fill=df[["filter"]])) +
    theme_classic() +
    NoLegend() +
    labs(x=method_1, y=method_2) +
    ggtitle(paste(method_1, "vs", method_2)) +
    ylim(-1, 1) +
    xlim(-1, 1) +
    geom_abline(slope=1, intercept=0, color="red")
```

### Histogram of average ratios

```{r}
min_ratio <- 1.5
```

Of these gene pairs, we can look at the ratio for the average expression. 

I have set a minimum average ratio of `r min_ratio` to see how many pairs go past this threshold value.

```{r}
df <- comp_corr %>% subset((saver==0 & cscore!=0) | (saver!=0 & cscore==0))
df <- df %>% subset(Var1 != Var2)

filter_genes <- comp_n_cells %>% subset(rna < min_cells)
filter_genes <- row.names(filter_genes)
tmp <- comp_perc_cells %>% subset(rna < min_perc)
filter_genes <- unique(c(filter_genes, row.names(tmp)))

tmp <- comp_avg %>% subset(saver < min_exp)
tmp <- row.names(tmp)
genes_filter <- sort(unique(c(filter_genes, tmp)))

df <- df %>% mutate(filter = (Var1 %in% genes_filter) | (Var2 %in% genes_filter))
df <- df %>% subset(filter == FALSE)

comp_avg$gene <- row.names(comp_avg)
comp_df <- df

idx <- match(comp_df$Var1, comp_avg$gene)
comp_df$Var1_avg <- comp_avg[idx, method]

idx <- match(comp_df$Var2, comp_avg$gene)
comp_df$Var2_avg <- comp_avg[idx, method]

comp_df$avg_ratio <- comp_df$Var1_avg / comp_df$Var2_avg
comp_df <- comp_df %>% arrange(avg_ratio)

cols <- c("Var1", "Var2", "avg_ratio", method, "Var1_avg", "Var2_avg")
comp_df <- comp_df[cols] %>% arrange(desc(avg_ratio))
comp_df <- comp_df[!duplicated(cbind(t(apply(df[1:2], 1, sort)))), ]



ggplot(comp_df) +
    geom_histogram(aes(x=avg_ratio), bins=100, color="black", fill=palette[3]) +
    theme_classic() +
    ggtitle(glue("{method}: average expression ratio")) +
    geom_vline(xintercept = min_ratio, color="black", size=1.5, linetype="dashed")
```


# Overview

With the workflow as it stand now, we have identified correlated genes where there is agreement in both CS-CORE and SAVER results. 

Some careful consideration needs to be given on how to deal cases where one gene is much more highly expressed compared to the other as it has a tendency to skew the results.